{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from grid2op.Agent import RandomAgent\n",
    "from grid2op.Converter.IdToAct import IdToAct\n",
    "\n",
    "from grid2op import make\n",
    "from grid2op.Action.PlayableAction import PlayableAction\n",
    "from grid2op.Parameters import Parameters\n",
    "from grid2op.multi_agent.multiAgentEnv import MultiAgentEnv\n",
    "import re\n",
    "import numpy as np\n",
    "from grid2op.multi_agent.multi_agentExceptions import *\n",
    "\n",
    "from lightsim2grid import LightSimBackend\n",
    "bk_cls = LightSimBackend\n",
    "    \n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from grid2op.PlotGrid import PlotMatplot\n",
    "\n",
    "\n",
    "action_domains = {\n",
    "    'agent_0' : [0,1,2,3, 4],\n",
    "    'agent_1' : [5,6,7,8,9,10,11,12,13]\n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from grid2op.multi_agent.ma_typing import MAAgents\n",
    "from grid2op.Environment.BaseEnv import BaseEnv\n",
    "from grid2op.Agent.baseAgent import BaseAgent\n",
    "from grid2op.multi_agent.multiAgentEnv import MultiAgentEnv\n",
    "\n",
    "\n",
    "def _run_simple_actor(\n",
    "    env : BaseEnv,\n",
    "    actor : BaseAgent,\n",
    "    nb_episodes : int,\n",
    ") -> dict:\n",
    "    \n",
    "    T = np.zeros(nb_episodes, dtype = int)\n",
    "    obs = env.reset()\n",
    "    t = 0\n",
    "    \n",
    "    rewards_history = []\n",
    "    mean_rewards_history = np.zeros(nb_episodes)\n",
    "    std_rewards_history = np.zeros(nb_episodes)\n",
    "    cumulative_reward = np.zeros(nb_episodes)\n",
    "    \n",
    "    info_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    obs_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    done_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    actions_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    reward = 0\n",
    "    \n",
    "    for episode in range(nb_episodes):\n",
    "        while True:\n",
    "            t += 1\n",
    "            action = actor.act(observation = obs, reward = reward)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "\n",
    "            rewards_history.append(reward)\n",
    "            info_history[episode].append(info.copy())\n",
    "            obs_history[episode].append(obs.copy())\n",
    "            done_history[episode].append(done)\n",
    "            actions_history[episode].append(action.copy())\n",
    "            \n",
    "\n",
    "            if done:\n",
    "                mean_rewards_history[episode] = np.mean(rewards_history)\n",
    "                std_rewards_history[episode] = np.std(rewards_history)\n",
    "                cumulative_reward[episode] = np.sum(rewards_history)\n",
    "                obs = env.reset()\n",
    "                T[episode] = t\n",
    "                t = 0\n",
    "                break\n",
    "            \n",
    "    return {\n",
    "        'mean_rewards' : mean_rewards_history,\n",
    "        'std_rewards' : std_rewards_history,\n",
    "        'episode_len' : T,\n",
    "        'info_history' : info_history,\n",
    "        'obs_history' : obs_history,\n",
    "        'done_history' : done_history,\n",
    "        'actions' : actions_history,\n",
    "        'cumulative_reward' : cumulative_reward\n",
    "         \n",
    "        # TODO cum reward done\n",
    "        # TODO local actions\n",
    "    }\n",
    "\n",
    "def _run_ma_actors(\n",
    "    ma_env : MultiAgentEnv,\n",
    "    actors : MAAgents,\n",
    "    nb_episodes : int,\n",
    ") -> dict:\n",
    "    \n",
    "    T = np.zeros(nb_episodes, dtype = int)\n",
    "    obs = ma_env.reset()\n",
    "    t = 0\n",
    "    \n",
    "    rewards_history = []\n",
    "    mean_rewards_history = np.zeros(nb_episodes)\n",
    "    std_rewards_history = np.zeros(nb_episodes)\n",
    "    cumulative_reward = np.zeros(nb_episodes)\n",
    "    \n",
    "    info_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    #obs_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    done_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    actions_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    r = 0\n",
    "    \n",
    "    for episode in range(nb_episodes):\n",
    "        while True:\n",
    "            t += 1\n",
    "            actions = {\n",
    "                agent : actors[agent].act(observation = obs[agent], reward = r)\n",
    "                for agent in ma_env.agents\n",
    "            }\n",
    "            obs, reward, dones, info = ma_env.step(actions)\n",
    "\n",
    "            r = reward[ma_env.agents[0]]\n",
    "            rewards_history.append(r)\n",
    "            info_history[episode].append(info[ma_env.agents[0]].copy())\n",
    "            #obs_history[episode].append(obs[ma_env.agents[0]].copy())\n",
    "            done_history[episode].append(dones[ma_env.agents[0]])\n",
    "            actions_history[episode].append(ma_env.global_action.copy())\n",
    "                \n",
    "\n",
    "            if dones[ma_env.agents[0]]:\n",
    "                mean_rewards_history[episode] = np.mean(rewards_history)\n",
    "                std_rewards_history[episode] =  np.std(rewards_history)\n",
    "                cumulative_reward[episode] = np.sum(rewards_history)\n",
    "                \n",
    "                obs = ma_env.reset()\n",
    "                T[episode] = t\n",
    "                t = 0\n",
    "                break\n",
    "            \n",
    "    return {\n",
    "        'mean_rewards' : mean_rewards_history,\n",
    "        'std_rewards' : std_rewards_history,\n",
    "        'episode_len' : T,\n",
    "        'info_history' : info_history,\n",
    "        #'obs_history' : obs_history,\n",
    "        'done_history' : done_history,\n",
    "        'actions' : actions_history,\n",
    "        'cumulative_reward' : cumulative_reward\n",
    "    }\n",
    "\n",
    "    \n",
    "def compare_simple_and_multi(\n",
    "    ma_env : BaseEnv, # It is grid2op.multi_agent.multiAgentEnv.MultiAgentEnv\n",
    "    simple_actor : BaseAgent, \n",
    "    ma_actors : MAAgents, \n",
    "    episodes : int = 2,\n",
    "    seed = 0,\n",
    "    chronics_id = 0,\n",
    "    save_path = \"./\"\n",
    "    ):\n",
    "    \n",
    "    #ma_env = MultiAgentEnv(env, action_domains, copy_env=False)\n",
    "    \n",
    "    ma_env.seed(seed)\n",
    "    ma_env._cent_env.set_id(chronics_id)\n",
    "    \n",
    "    results_simple = _run_simple_actor(ma_env._cent_env, simple_actor, episodes)\n",
    "    results_ma = _run_ma_actors(ma_env, ma_actors, episodes)\n",
    "    \n",
    "    #save results\n",
    "    # TODO\n",
    "    \n",
    "    return results_simple, results_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.multi_agent.ma_typing import LocalObservation\n",
    "from grid2op.Agent import BaseAgent\n",
    "\n",
    "class DisconnectorLocalObs(BaseAgent):\n",
    "    def __init__(self,\n",
    "                 action_space,\n",
    "                 is_local = False,\n",
    "                 threshold_powerFlow_safe = 1.,\n",
    "                 **kwargs):\n",
    "        super().__init__(action_space)\n",
    "        self.lines_disconnected = set()\n",
    "        self.action_space = action_space\n",
    "        self.threshold_powerFlow_safe = threshold_powerFlow_safe\n",
    "        self.is_local = is_local\n",
    "\n",
    "        \n",
    "    def act(self, observation : LocalObservation, reward, done = False):\n",
    "\n",
    "        # Look for overloads and rank them\n",
    "        #ltc_list = self.getRankedOverloads(observation)\n",
    "        #counterTestedOverloads = 0\n",
    "        overloaded = (observation.rho >= self.threshold_powerFlow_safe)\n",
    "        \n",
    "        if not np.any(overloaded):\n",
    "            return self.action_space({})\n",
    "        else:\n",
    "            action = self.action_space({})\n",
    "            \n",
    "            overloaded_lines = np.where(overloaded)[0]\n",
    "            \n",
    "            for lineid in overloaded_lines:\n",
    "                action.set_line_status = [(lineid, -1)]\n",
    "                break\n",
    "                \n",
    "            return action\n",
    "            \n",
    "    def reset(self, observation):\n",
    "        # No internal states to reset\n",
    "        pass\n",
    "\n",
    "    def load(self, path):\n",
    "        # Nothing to load\n",
    "        pass\n",
    "\n",
    "    def save(self, path):\n",
    "        # Nothing to save\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najarfar/Internship/Grid2Op/grid2op/MakeEnv/Make.py:394: UserWarning: You are using a development environment. This environment is not intended for training agents. It might not be up to date and its primary use if for tests (hence the \"test=True\" you passed as argument). Use at your own risk.\n",
      "  warnings.warn(_MAKE_DEV_ENV_WARN)\n",
      "/home/najarfar/Internship/Grid2Op/grid2op/multi_agent/multiAgentEnv.py:123: UserWarning: Rules can not be changed in this version.\n",
      "  warnings.warn(\"Rules can not be changed in this version.\")\n",
      "/home/najarfar/Internship/Grid2Op/grid2op/multi_agent/multiAgentEnv.py:129: UserWarning: The central env has been heavily modified (parameters and reset) !\n",
      "  warnings.warn(\"The central env has been heavily modified (parameters and reset) !\")\n"
     ]
    }
   ],
   "source": [
    "env_name = \"l2rpn_case14_sandbox\"#\"educ_case14_storage\"\n",
    "env = make(env_name, test=True, backend=bk_cls(),\n",
    "                action_class=PlayableAction, _add_to_name=\"_test_ma\", )\n",
    "\n",
    "observation_domains = action_domains.copy()\n",
    "ma_env = MultiAgentEnv(env, action_domains, observation_domains=observation_domains, copy_env=False)\n",
    "\n",
    "simple_actor = DisconnectorLocalObs(ma_env._cent_env.action_space, threshold_powerFlow_safe=0.9)\n",
    "ma_actors = {\n",
    "    agent : DisconnectorLocalObs(ma_env.action_spaces[agent], is_local=True, threshold_powerFlow_safe=0.9)\n",
    "    for agent in ma_env.agents\n",
    "}\n",
    "\n",
    "assert ma_env._is_global_obs == False\n",
    "\n",
    "results_simple, results_ma = compare_simple_and_multi(\n",
    "    ma_env=ma_env,\n",
    "    simple_actor=simple_actor,\n",
    "    ma_actors=ma_actors,\n",
    "    episodes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66.81484985 66.80235291]\n"
     ]
    }
   ],
   "source": [
    "print(results_ma['mean_rewards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(np.array([0,3])+0.5,results_simple['mean_rewards'], label = 'simple')\n",
    "plt.bar(np.array([0,3])-0.5,results_ma['mean_rewards'], label = 'ma')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9695fee56864081dd9787bed9cb2ecf5768f301e19b28b0d4bc6bbab594eacc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('grid2op')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
