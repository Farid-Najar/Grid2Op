{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najarfar/Internship/Grid2Op/grid2op/MakeEnv/Make.py:394: UserWarning: You are using a development environment. This environment is not intended for training agents. It might not be up to date and its primary use if for tests (hence the \"test=True\" you passed as argument). Use at your own risk.\n",
      "  warnings.warn(_MAKE_DEV_ENV_WARN)\n",
      "/home/najarfar/Internship/Grid2Op/grid2op/multi_agent/multiAgentEnv.py:123: UserWarning: Rules can not be changed in this version.\n",
      "  warnings.warn(\"Rules can not be changed in this version.\")\n",
      "/home/najarfar/Internship/Grid2Op/grid2op/multi_agent/multiAgentEnv.py:129: UserWarning: The central env has been heavily modified (parameters and reset) !\n",
      "  warnings.warn(\"The central env has been heavily modified (parameters and reset) !\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from grid2op.Agent import RandomAgent\n",
    "from grid2op.Converter.IdToAct import IdToAct\n",
    "\n",
    "from grid2op import make\n",
    "from grid2op.Action.PlayableAction import PlayableAction\n",
    "from grid2op.multi_agent.multiAgentEnv import MultiAgentEnv\n",
    "import numpy as np\n",
    "from grid2op.multi_agent.multi_agentExceptions import *\n",
    "\n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "from lightsim2grid import LightSimBackend\n",
    "bk_cls = LightSimBackend\n",
    "\n",
    "action_domains = {\n",
    "    'agent_0' : [0,1,2,3, 4],\n",
    "    'agent_1' : [5,6,7,8,9,10,11,12,13]\n",
    "}\n",
    "env_name = \"l2rpn_case14_sandbox\"#\"educ_case14_storage\"\n",
    "env = make(env_name, test=True, backend = bk_cls(),\n",
    "                action_class=PlayableAction, _add_to_name=\"_test_ma\")\n",
    "\n",
    "\n",
    "ma_env = MultiAgentEnv(env, action_domains, copy_env=False)\n",
    "\n",
    "ma_env.seed(0)\n",
    "obs = ma_env.reset()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from grid2op.multi_agent.ma_typing import MAAgents\n",
    "from grid2op.Environment.BaseEnv import BaseEnv\n",
    "from grid2op.Agent.baseAgent import BaseAgent\n",
    "from grid2op.multi_agent.multiAgentEnv import MultiAgentEnv\n",
    "\n",
    "\n",
    "def _run_simple_actor(\n",
    "    env : BaseEnv,\n",
    "    actor : BaseAgent,\n",
    "    nb_episodes : int,\n",
    ") -> dict:\n",
    "    \n",
    "    T = np.zeros(nb_episodes, dtype = int)\n",
    "    obs = env.reset()\n",
    "    t = 0\n",
    "    \n",
    "    rewards_history = []\n",
    "    mean_rewards_history = np.zeros(nb_episodes)\n",
    "    std_rewards_history = np.zeros(nb_episodes)\n",
    "    cumulative_reward = np.zeros(nb_episodes)\n",
    "    \n",
    "    info_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    obs_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    done_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    actions_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    reward = 0\n",
    "    \n",
    "    for episode in range(nb_episodes):\n",
    "        while True:\n",
    "            t += 1\n",
    "            action = actor.act(observation = obs, reward = reward)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            \n",
    "            #obs._obs_env = None\n",
    "\n",
    "            rewards_history.append(reward)\n",
    "            info_history[episode].append(info.copy())\n",
    "            obs_history[episode].append(obs)\n",
    "            done_history[episode].append(done)\n",
    "            actions_history[episode].append(action)\n",
    "            \n",
    "\n",
    "            if done:\n",
    "                mean_rewards_history[episode] = np.mean(rewards_history)\n",
    "                std_rewards_history[episode] = np.std(rewards_history)\n",
    "                cumulative_reward[episode] = np.sum(rewards_history)\n",
    "                obs = env.reset()\n",
    "                T[episode] = t\n",
    "                t = 0\n",
    "                break\n",
    "            \n",
    "    return {\n",
    "        'mean_rewards' : mean_rewards_history,\n",
    "        'std_rewards' : std_rewards_history,\n",
    "        'episode_len' : T,\n",
    "        'info_history' : info_history,\n",
    "        'obs_history' : obs_history,\n",
    "        'done_history' : done_history,\n",
    "        'actions' : actions_history,\n",
    "        'cumulative_reward' : cumulative_reward\n",
    "         \n",
    "        # TODO cum reward done\n",
    "        # TODO local actions\n",
    "    }\n",
    "\n",
    "def _run_ma_actors(\n",
    "    ma_env : MultiAgentEnv,\n",
    "    actors : MAAgents,\n",
    "    nb_episodes : int,\n",
    ") -> dict:\n",
    "    \n",
    "    T = np.zeros(nb_episodes, dtype = int)\n",
    "    obs = ma_env.reset()\n",
    "    t = 0\n",
    "    \n",
    "    rewards_history = []\n",
    "    mean_rewards_history = np.zeros(nb_episodes)\n",
    "    std_rewards_history = np.zeros(nb_episodes)\n",
    "    cumulative_reward = np.zeros(nb_episodes)\n",
    "    \n",
    "    info_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    obs_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    done_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    actions_history = [[] for _ in range(nb_episodes)]\n",
    "    \n",
    "    r = 0\n",
    "    \n",
    "    for episode in range(nb_episodes):\n",
    "        while True:\n",
    "            t += 1\n",
    "            actions = {\n",
    "                agent : actors[agent].act(observation = obs[agent], reward = r)\n",
    "                for agent in ma_env.agents\n",
    "            }\n",
    "            obs, reward, dones, info = ma_env.step(actions)\n",
    "\n",
    "            r = reward[ma_env.agents[0]]\n",
    "            rewards_history.append(r)\n",
    "            info_history[episode].append(info[ma_env.agents[0]].copy())\n",
    "            \n",
    "            for agent in ma_env.agents:\n",
    "                # TODO pourquoi ce probl√®me ?\n",
    "                obs[agent]._obs_env = None\n",
    "                \n",
    "            obs_history[episode].append(obs[ma_env.agents[0]])\n",
    "            done_history[episode].append(dones[ma_env.agents[0]])\n",
    "            actions_history[episode].append(ma_env.global_action)\n",
    "                \n",
    "\n",
    "            if dones[ma_env.agents[0]]:\n",
    "                mean_rewards_history[episode] = np.mean(rewards_history)\n",
    "                std_rewards_history[episode] =  np.std(rewards_history)\n",
    "                cumulative_reward[episode] = np.sum(rewards_history)\n",
    "                \n",
    "                obs = ma_env.reset()\n",
    "                T[episode] = t\n",
    "                t = 0\n",
    "                break\n",
    "            \n",
    "    return {\n",
    "        'mean_rewards' : mean_rewards_history,\n",
    "        'std_rewards' : std_rewards_history,\n",
    "        'episode_len' : T,\n",
    "        'info_history' : info_history,\n",
    "        'obs_history' : obs_history,\n",
    "        'done_history' : done_history,\n",
    "        'actions' : actions_history,\n",
    "        'cumulative_reward' : cumulative_reward\n",
    "    }\n",
    "\n",
    "    \n",
    "def compare_simple_and_multi(\n",
    "    env : BaseEnv, # It is grid2op.multi_agent.multiAgentEnv.MultiAgentEnv\n",
    "    simple_actor : BaseAgent, \n",
    "    ma_actors : MAAgents, \n",
    "    episodes : int = 2,\n",
    "    seed = 0,\n",
    "    chronics_id = 0,\n",
    "    save_path = \"./\"\n",
    "    ):\n",
    "    \n",
    "    ma_env = MultiAgentEnv(env, action_domains, copy_env=True)\n",
    "    \n",
    "    ma_env.seed(seed)\n",
    "    ma_env._cent_env.set_id(chronics_id)\n",
    "    \n",
    "    results_simple = _run_simple_actor(ma_env._cent_env, simple_actor, episodes)\n",
    "    results_ma = _run_ma_actors(ma_env, ma_actors, episodes)\n",
    "    \n",
    "    #save results\n",
    "    # TODO\n",
    "    \n",
    "    return results_simple, results_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najarfar/Internship/Grid2Op/grid2op/multi_agent/multiAgentEnv.py:123: UserWarning: Rules can not be changed in this version.\n",
      "  warnings.warn(\"Rules can not be changed in this version.\")\n",
      "/home/najarfar/Internship/Grid2Op/grid2op/multi_agent/multiAgentEnv.py:123: UserWarning: Rules can not be changed in this version.\n",
      "  warnings.warn(\"Rules can not be changed in this version.\")\n",
      "/home/najarfar/Internship/Grid2Op/grid2op/multi_agent/multiAgentEnv.py:123: UserWarning: Rules can not be changed in this version.\n",
      "  warnings.warn(\"Rules can not be changed in this version.\")\n",
      "/home/najarfar/Internship/Grid2Op/grid2op/multi_agent/multiAgentEnv.py:123: UserWarning: Rules can not be changed in this version.\n",
      "  warnings.warn(\"Rules can not be changed in this version.\")\n",
      "/home/najarfar/Internship/Grid2Op/grid2op/multi_agent/multiAgentEnv.py:123: UserWarning: Rules can not be changed in this version.\n",
      "  warnings.warn(\"Rules can not be changed in this version.\")\n",
      "/home/najarfar/Internship/Grid2Op/grid2op/multi_agent/multiAgentEnv.py:123: UserWarning: Rules can not be changed in this version.\n",
      "  warnings.warn(\"Rules can not be changed in this version.\")\n",
      "/home/najarfar/Internship/Grid2Op/grid2op/multi_agent/multiAgentEnv.py:123: UserWarning: Rules can not be changed in this version.\n",
      "  warnings.warn(\"Rules can not be changed in this version.\")\n",
      "/home/najarfar/Internship/Grid2Op/grid2op/multi_agent/multiAgentEnv.py:123: UserWarning: Rules can not be changed in this version.\n",
      "  warnings.warn(\"Rules can not be changed in this version.\")\n",
      "/home/najarfar/Internship/Grid2Op/grid2op/multi_agent/multiAgentEnv.py:123: UserWarning: Rules can not be changed in this version.\n",
      "  warnings.warn(\"Rules can not be changed in this version.\")\n",
      "/home/najarfar/Internship/Grid2Op/grid2op/multi_agent/multiAgentEnv.py:123: UserWarning: Rules can not be changed in this version.\n",
      "  warnings.warn(\"Rules can not be changed in this version.\")\n"
     ]
    }
   ],
   "source": [
    "from grid2op.Agent import RandomAgent, DoNothingAgent\n",
    "simple_actor = RandomAgent(env.action_space)\n",
    "\n",
    "for _ in range(10):\n",
    "    ma_actors = dict()\n",
    "    for agent_nm in ma_env.agents:\n",
    "        IdToActThis = ma_env.action_spaces[agent_nm].make_local(IdToAct)\n",
    "        #assert IdToActThis.agent_name == agent_nm    \n",
    "        ma_actors[agent_nm] = RandomAgent(ma_env.action_spaces[agent_nm],\n",
    "                                       action_space_converter=IdToActThis\n",
    "                                       )\n",
    "    \n",
    "    \n",
    "    results_simple, results_ma = compare_simple_and_multi(\n",
    "        env=env,\n",
    "        simple_actor=simple_actor,\n",
    "        ma_actors=ma_actors,\n",
    "        # TODO plus d'episodes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ma['']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9695fee56864081dd9787bed9cb2ecf5768f301e19b28b0d4bc6bbab594eacc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('grid2op')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
